{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5044d-794c-4bfa-9725-d5e7d0f7d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from perception_bev_learning.utils import load_pkl\n",
    "from os.path import join\n",
    "\n",
    "EXPERIMENT_FOLDER = \"/Data/Results/bev_learning/debug/train/full_testing\"\n",
    "\n",
    "\n",
    "pkl_files = [str(s) for s in Path(EXPERIMENT_FOLDER).glob(\"*.pkl\")]\n",
    "\n",
    "# LOAD DATA\n",
    "hdd = {s.split(\"__\")[-1][:-4]: load_pkl(s) for s in pkl_files if s.find(\"hdd\") != -1}\n",
    "layer_statistics = {\n",
    "    s.split(\"__\")[-1][:-4]: load_pkl(s) for s in pkl_files if s.find(\"statistic_reverted_layer_scaling\") != -1\n",
    "}\n",
    "metrics = {s.split(\"__\")[-1][:-4]: load_pkl(s) for s in pkl_files if s.find(\"meter_results\") != -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49fc71-ca38-46ff-b2aa-61a80ec7222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"test\"\n",
    "metrics[MODE].keys()\n",
    "\n",
    "[k for k in layer_statistics[\"test\"].keys() if k.find(\"obser\") != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77d802-7a8e-4867-a4e5-1936c1a5d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Metric\", \"Value\"]\n",
    "for k, v in metrics[MODE].items():\n",
    "    if k.find(\"_step\") == -1:\n",
    "        x.add_row([k, round(v, 4)])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e40b6-af9a-438b-82de-6816797731c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "\n",
    "\n",
    "data = {\"name\": [], \"mode\": [], \"metric\": [], \"layer\": [], \"value\": []}\n",
    "for MODE in [\"train\", \"test\", \"val\"]:\n",
    "    for k, v in metrics[MODE].items():\n",
    "        if k.find(\"step\") != -1:\n",
    "            continue\n",
    "        i1 = k.find(\"_pred\")\n",
    "        if i1 == -1:\n",
    "            i1 = k.find(\"_current\")\n",
    "\n",
    "        i2 = k.find(\"__\")\n",
    "\n",
    "        data[\"layer\"].append(k[5:i1])\n",
    "        data[\"name\"].append(k[i1 + 1 : i2])\n",
    "        data[\"value\"].append(v)\n",
    "        data[\"mode\"].append(MODE)\n",
    "        data[\"metric\"].append(k[i2 + 2 : -6])\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df[(df[\"mode\"] == \"test\") * (df[\"layer\"] == \"elevation\") * (df[\"metric\"] == \"mae\")]\n",
    "metrics[MODE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e1047-baf2-474a-b6f9-8c8789a1a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "for MODE in [\"train\", \"val\", \"test\"]:\n",
    "\n",
    "    # Filter metrics based on keywords\n",
    "    filtered_elevation_metrics = {}\n",
    "    filtered_wheel_risk_cvar_metrics = {}\n",
    "\n",
    "    for k, v in metrics[MODE].items():\n",
    "        if \"pred_target\" in k or \"current_target\" in k:\n",
    "            if (\"_mae_\" in k or \"_wmae_\" in k) and \"elevation\" in k:\n",
    "                if \"_epoch\" in k:\n",
    "                    filtered_elevation_metrics[k] = v\n",
    "            elif (\"_mse_\" in k or \"_wmse_\" in k) and \"wheel_risk_cvar\" in k:\n",
    "                if \"_epoch\" in k:\n",
    "                    filtered_wheel_risk_cvar_metrics[k] = v\n",
    "\n",
    "    # Extract metric names and values for plotting\n",
    "    elevation_metric_names = list(filtered_elevation_metrics.keys())\n",
    "    elevation_metric_values = list(filtered_elevation_metrics.values())\n",
    "\n",
    "    wheel_risk_cvar_metric_names = list(filtered_wheel_risk_cvar_metrics.keys())\n",
    "    wheel_risk_cvar_metric_values = list(filtered_wheel_risk_cvar_metrics.values())\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "    # Bar plot for elevation metrics\n",
    "    elevation_bar_colors = [\"blue\" if \"current_target\" in metric else \"orange\" for metric in elevation_metric_names]\n",
    "    axes[0].bar(\n",
    "        range(len(elevation_metric_names)),\n",
    "        elevation_metric_values,\n",
    "        align=\"center\",\n",
    "        alpha=0.7,\n",
    "        color=elevation_bar_colors,\n",
    "    )\n",
    "    axes[0].set_xticks(range(len(elevation_metric_names)))\n",
    "    axes[0].set_xticklabels(elevation_metric_names, rotation=0)\n",
    "    axes[0].set_xlabel(\"Metric\")\n",
    "    axes[0].set_ylabel(\"Value\")\n",
    "    axes[0].set_title(\"Elevation Metrics\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Bar plot for wheel risk cvar metrics\n",
    "    wheel_risk_cvar_bar_colors = [\n",
    "        \"blue\" if \"current_target\" in metric else \"orange\" for metric in wheel_risk_cvar_metric_names\n",
    "    ]\n",
    "    axes[1].bar(\n",
    "        range(len(wheel_risk_cvar_metric_names)),\n",
    "        wheel_risk_cvar_metric_values,\n",
    "        align=\"center\",\n",
    "        alpha=0.7,\n",
    "        color=wheel_risk_cvar_bar_colors,\n",
    "    )\n",
    "    axes[1].set_xticks(range(len(wheel_risk_cvar_metric_names)))\n",
    "    axes[1].set_xticklabels(wheel_risk_cvar_metric_names, rotation=0)\n",
    "    axes[1].set_xlabel(\"Metric\")\n",
    "    axes[1].set_ylabel(\"Value\")\n",
    "    axes[1].set_title(\"Wheel Risk CVaR Metrics\")\n",
    "    axes[1].grid(True)\n",
    "    axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    fig.suptitle(f\"Metrics for MODE: {MODE}\", fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f59b1b-0374-41df-bfd2-c9d124f511c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception_bev_learning.dataset import get_bev_dataloader\n",
    "from perception_bev_learning.cfg import ExperimentParams\n",
    "from perception_bev_learning.utils import denormalize_img\n",
    "from perception_bev_learning.visu import LearningVisualizer, show\n",
    "from perception_bev_learning.visu import show, get_img_from_fig\n",
    "from pytorch_lightning import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "from perception_bev_learning.visu import paper_colors_rgb_f\n",
    "\n",
    "LAYER = \"wheel_risk_cvar\"\n",
    "KEY = \"bev_metric\"\n",
    "\n",
    "METRICS = [\"pred_target__cell_stat\", \"current_target__cell_stat\"]\n",
    "for MODE in [\"train\", \"val\", \"test\"]:  # , \"val\", \"train\"]:\n",
    "    fig, axes = plt.subplots(1, len(METRICS), sharey=True, figsize=(10, 5))  # Create subplots\n",
    "    print(LAYER)\n",
    "    for j, METRIC in enumerate(METRICS):\n",
    "        # stat = \"pred_statistics\"\n",
    "        # stat = \"current_statistics\"\n",
    "\n",
    "        recall = layer_statistics[MODE][f\"{METRIC}_{KEY}_{LAYER}_test_recall_bins\"]\n",
    "        f1 = layer_statistics[MODE][f\"{METRIC}_{KEY}_{LAYER}_test_f1_bins\"]\n",
    "        precision = layer_statistics[MODE][f\"{METRIC}_{KEY}_{LAYER}_test_precision_bins\"]\n",
    "        x_values = np.arange(0, len(f1)) + 1\n",
    "        # Create a figure and a set of subplots\n",
    "\n",
    "        # Plot hazard_detection_ratio\n",
    "        axes[j].plot(x_values, [r[1] for r in recall], label=\"Recall\", color=list(paper_colors_rgb_f[\"orange\"]))\n",
    "        # Plot false_hazard_ratio\n",
    "        axes[j].plot(x_values, [r[1] for r in f1], label=\"F1\", color=list(paper_colors_rgb_f[\"mangenta\"]))\n",
    "        axes[j].plot(x_values, [r[1] for r in precision], label=\"Precision\", color=list(paper_colors_rgb_f[\"blue\"]))\n",
    "\n",
    "        # Set labels and title\n",
    "        axes[j].set_xlabel(\"Distance in m\")\n",
    "        axes[j].set_ylabel(\"Metric\")\n",
    "        axes[j].set_title(f\"{MODE} - {METRIC} Binning Results\")\n",
    "        axes[j].legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65dea1b-98f2-42dc-8d37-5177b49db897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception_bev_learning.dataset import get_bev_dataloader\n",
    "from perception_bev_learning.cfg import ExperimentParams\n",
    "from perception_bev_learning.utils import denormalize_img\n",
    "from perception_bev_learning.visu import LearningVisualizer, show\n",
    "from perception_bev_learning.visu import show, get_img_from_fig\n",
    "from pytorch_lightning import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "from perception_bev_learning.visu import paper_colors_rgb_f\n",
    "\n",
    "LAYER = \"elevation\"\n",
    "KEY = \"bev_metric\"\n",
    "\n",
    "METRICS = [\"pred_target__observed_mae\", \"current_target__observed_mae\"]\n",
    "for MODE in [\"train\"]:  # , \"val\", \"train\"]: \"train\", \"val\",\n",
    "    fig, axes = plt.subplots(1, len(METRICS), sharey=True, figsize=(10, 5))  # Create subplots\n",
    "    print(LAYER)\n",
    "    for j, METRIC in enumerate(METRICS):\n",
    "        # stat = \"pred_statistics\"\n",
    "        # stat = \"current_statistics\"\n",
    "        # print(\"current_target__unobserved_mse_bev_metric_wheel_risk_cvar_test\")\n",
    "        print(f\"{METRIC}:\")\n",
    "        print(layer_statistics[MODE][f\"{METRIC}_{KEY}_{LAYER}_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c31c0e-f0ef-4ccc-b879-331a097572a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b16b05-fc9e-4406-a57c-e1bb76a0f065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ed80b-2896-4c4e-ba54-b60d58a77b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perception_bev_learning.dataset import get_bev_dataloader\n",
    "from perception_bev_learning.cfg import ExperimentParams\n",
    "from perception_bev_learning.utils import denormalize_img\n",
    "from perception_bev_learning.visu import LearningVisualizer, show\n",
    "from perception_bev_learning.visu import show, get_img_from_fig\n",
    "from pytorch_lightning import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "from perception_bev_learning.visu import paper_colors_rgb_f\n",
    "\n",
    "\n",
    "METRICS = [\"pred_target__cell_stat\", \"current_target__cell_stat\"]\n",
    "cut_off = 50\n",
    "for MODE in [\"train\", \"val\", \"test\"]:  # , \"val\", \"train\"]:\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, sharey=False, figsize=(14, 3), constrained_layout=False)  # Create subplots\n",
    "\n",
    "    for k, value in enumerate([\"precision\", \"recall\", \"f1\"]):\n",
    "        for res in zip([\"mangenta\", \"orange\"], METRICS, [\"RoadRunner\", \"RACER-X\"]):\n",
    "            if k < 3:\n",
    "\n",
    "                color, METRIC, axes_label = res\n",
    "                LAYER = \"wheel_risk_cvar\"\n",
    "                KEY = \"bev_metric\"\n",
    "\n",
    "                met = layer_statistics[MODE][f\"{METRIC}_{KEY}_{LAYER}_test_{value}_bins\"]\n",
    "\n",
    "                x_values = np.arange(0, cut_off) + 1\n",
    "                # Create a figure and a set of subplots\n",
    "\n",
    "                # Plot hazard_detection_ratio\n",
    "                axes[k].plot(\n",
    "                    x_values, [r[1] for r in met][:cut_off], label=axes_label, color=list(paper_colors_rgb_f[color])\n",
    "                )\n",
    "\n",
    "                # Set labels and title\n",
    "                axes[k].set_xlabel(\"Distance in [m]\")\n",
    "                axes[k].set_ylabel(value.capitalize())\n",
    "                axes[k].set_title(f\"Hazard Detection: {value.capitalize()}\")\n",
    "                axes[k].legend()\n",
    "                axes[k].legend(fontsize=10)\n",
    "                # axes[k].spines['top'].set_visible(False)\n",
    "                # axes[k].spines['right'].set_visible(False)\n",
    "\n",
    "                axes[k].set_ylim(bottom=0)\n",
    "                axes[k].set_ylim(top=1)\n",
    "                axes[k].set_xlim(left=0)\n",
    "\n",
    "    # MSE plot\n",
    "    METRIC_CUR = \"current_target__cell_stat\"\n",
    "    METRIC_TAR = \"pred_target__cell_stat\"\n",
    "    mean_tar = layer_statistics[MODE][f\"{METRIC_TAR}_{KEY}_{LAYER}_test_mean_bins\"]\n",
    "    mean_cur = layer_statistics[MODE][f\"{METRIC_CUR}_{KEY}_{LAYER}_test_mean_bins\"]\n",
    "\n",
    "    # Plot hazard_detection_ratio\n",
    "    axes[3].plot(x_values, mean_tar[:cut_off], label=f\"RoadRunner\", color=list(paper_colors_rgb_f[\"mangenta\"]))\n",
    "    axes[3].plot(x_values, mean_cur[:cut_off], label=f\"RACER-X\", color=list(paper_colors_rgb_f[\"orange\"]))\n",
    "\n",
    "    # Set labels and title\n",
    "    axes[3].set_xlabel(\"Distance in [m]\", fontsize=12)\n",
    "    axes[3].set_ylabel(\"MSE\", fontsize=12)\n",
    "    axes[3].set_title(f\"Layer {LAYER}: MSE\")\n",
    "    axes[3].legend(fontsize=10)\n",
    "    axes[3].grid(True)\n",
    "    axes[3].set_ylim(bottom=0)\n",
    "\n",
    "    axes[3].set_ylim(top=0.2)\n",
    "    axes[3].set_xlim(left=0)\n",
    "\n",
    "    # axes[1].set_yticklabels([])\n",
    "    # axes[2].set_yticklabels([])\n",
    "    # plt.subplots_adjust(wspace=0.0)\n",
    "    # Display the plot\n",
    "    # print(MODE)\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "    plt.savefig(join(EXPERIMENT_FOLDER, f\"hazard_detection_metric_{MODE}.svg\"), format=\"svg\")\n",
    "    plt.savefig(join(EXPERIMENT_FOLDER, f\"hazard_detection_metric_{MODE}.pdf\"), format=\"pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d579af3-9c89-45a4-9857-f75b1e54b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for res in zip([\"wheel_risk_cvar\", \"elevation\"], [\"MSE in [m2]\", \"MAE in [m]\"]):\n",
    "    LAYER, y_label = res\n",
    "    MODES = [\"train\", \"val\", \"test\"]\n",
    "    KEY = \"bev_metric\"\n",
    "    METRIC_CUR = \"current_target__cell_stat\"\n",
    "    METRIC_TAR = \"pred_target__cell_stat\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(MODES), sharey=True, figsize=(10, 3))  # Create subplots\n",
    "\n",
    "    for idx, MODE in enumerate(MODES):\n",
    "        mean_tar = layer_statistics[MODE][f\"{METRIC_TAR}_{KEY}_{LAYER}_test_mean_bins\"]\n",
    "        mean_cur = layer_statistics[MODE][f\"{METRIC_CUR}_{KEY}_{LAYER}_test_mean_bins\"]\n",
    "\n",
    "        x_values = np.arange(0, len(mean_cur)) + 1\n",
    "\n",
    "        # Plot hazard_detection_ratio\n",
    "        axes[idx].plot(x_values, mean_tar, label=f\"RoadRunner\", color=list(paper_colors_rgb_f[\"mangenta\"]))\n",
    "        axes[idx].plot(x_values, mean_cur, label=f\"RACER-X\", color=list(paper_colors_rgb_f[\"orange\"]))\n",
    "\n",
    "        # Set labels and title\n",
    "        axes[idx].set_xlabel(\"Distance in [m]\", fontsize=12)\n",
    "        axes[idx].set_ylabel(y_label, fontsize=12)\n",
    "        axes[idx].set_title(f\"Layer: {LAYER} - Mode: {MODE}\")\n",
    "        axes[idx].legend(fontsize=12)\n",
    "        axes[idx].grid(True)\n",
    "        axes[idx].set_ylim(bottom=0)\n",
    "        if LAYER == \"wheel_risk_cvar\":\n",
    "            axes[idx].set_ylim(top=0.2)\n",
    "        else:\n",
    "            axes[idx].set_ylim(top=2)\n",
    "        axes[idx].set_xlim(left=0)\n",
    "\n",
    "        # axes[idx].spines['top'].set_visible(False)\n",
    "        # axes[idx].spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "    plt.savefig(join(EXPERIMENT_FOLDER, f\"{LAYER}_distance.svg\"), format=\"svg\")\n",
    "    plt.savefig(join(EXPERIMENT_FOLDER, f\"{LAYER}_distance.pdf\"), format=\"pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60086cb5-20de-4fbb-aaf3-938e15de0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MODE)\n",
    "MODE = \"test\"\n",
    "for MODE in [\"test\", \"train\"]:\n",
    "    layer_statistics[MODE].keys()\n",
    "\n",
    "    visu = LearningVisualizer(p_visu=EXPERIMENT_FOLDER)\n",
    "\n",
    "    i1 = visu.plot_elevation_map_two(\n",
    "        layer_statistics[MODE][\"current_target__cell_stat_bev_metric_wheel_risk_cvar_test_mean_map\"],\n",
    "        layer_statistics[MODE][\"pred_target__cell_stat_bev_metric_wheel_risk_cvar_test_mean_map\"],\n",
    "        tag=f\"{MODE}_epoch_statistic_mae_current_pred_wheel_risk\",\n",
    "        cmap_name=\"turbo\",\n",
    "        v_max=1,\n",
    "        v_min=0,\n",
    "        labels=[\"RACER-X\", \"RoadRunner\"],\n",
    "        title=\"MSE - wheel_risk_cvar\",\n",
    "        store_svg=True,\n",
    "    )\n",
    "\n",
    "    def max_nan(t):\n",
    "        m = ~torch.isnan(t)\n",
    "        return t[m].max()\n",
    "\n",
    "    current_mean = layer_statistics[MODE][\"current_target__cell_stat_bev_metric_elevation_test_mean_map\"]\n",
    "    pred_mean = layer_statistics[MODE][\"pred_target__cell_stat_bev_metric_elevation_test_mean_map\"]\n",
    "    ma = round(float(max(max_nan(current_mean), max_nan(pred_mean))), 3)\n",
    "\n",
    "    i2 = visu.plot_elevation_map_two(\n",
    "        current_mean,\n",
    "        pred_mean,\n",
    "        tag=f\"{MODE}_epoch_statistic_mae_current_pred_elevation\",\n",
    "        cmap_name=\"turbo\",\n",
    "        v_max=2.5,\n",
    "        v_min=0,\n",
    "        labels=[\"RACER-X\", \"RoadRunner\"],\n",
    "        title=\"MSE - wheel_risk_cvar\",\n",
    "        subtitle=False,\n",
    "        store_svg=True,\n",
    "    )\n",
    "    show(i1, title=f\"{MODE} - Wheel_Risk\"), show(i2, title=f\"{MODE} -Elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb5bea-3f7e-4595-a571-660fa956c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in layer_statistics[MODE].keys() if k.find(\"mean\") != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9ccc5-3535-48d3-be9d-a0e9a0a94fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metric = \"elevation\"\n",
    "for MODE in [\"test\", \"train\"]:\n",
    "    # 72meter is the max distance consired\n",
    "    current_mean_bins = layer_statistics[MODE][f\"{metric}_current_mean_bins\"][:50]\n",
    "    pred_mean_bins = layer_statistics[MODE][f\"{metric}_pred_mean_bins\"][:50]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    fig.suptitle(f\"{MODE.capitalize()} Data - {metric}\")\n",
    "\n",
    "    # Plot current bins\n",
    "    axs[0].bar(np.arange(len(current_mean_bins)), current_mean_bins * 20, color=\"blue\", label=\"Current Bins\")\n",
    "    axs[0].set_xlabel(\"Bins in meter\")\n",
    "    axs[0].set_ylabel(\"Values\")\n",
    "    axs[0].set_title(\"Racer-X Elevation MAE\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot predicted bins\n",
    "    axs[1].bar(np.arange(len(pred_mean_bins)), pred_mean_bins * 20, color=\"red\", label=\"Pred Bins\")\n",
    "    axs[1].set_xlabel(\"Bins in meter\")\n",
    "    axs[1].set_ylabel(\"Values\")\n",
    "    axs[1].set_title(\"RoadRunner Elevation MAE\")\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
